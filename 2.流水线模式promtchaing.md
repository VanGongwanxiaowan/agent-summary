
https://docs.google.com/document/d/1flxKGrbnF2g8yh3F-oVD5Xx7ZumId56HbFpIiPdkqLI/edit?usp=sharing

# 第1章：提示词链（Prompt Chaining）
## 提示词链模式概述
提示词链，有时也被称为“流水线模式（Pipeline Pattern）”，是在利用大型语言模型（LLMs）处理复杂任务时所采用的一种强大范式。它并非期望大型语言模型通过单一、整体的步骤解决复杂问题，而是主张采用“分而治之”的策略。其核心思路是将原本棘手的复杂问题拆解为一系列更小、更易于处理的子问题。每个子问题都通过专门设计的提示词单独解决，且前一个提示词生成的输出会被策略性地作为输入，传递到链中的下一个提示词。

这种顺序处理技术天然地为与大型语言模型的交互引入了模块化和清晰度。通过拆解复杂任务，我们能更轻松地理解和调试每个单独步骤，使整个流程更稳健、更具可解释性。链中的每个步骤都可经过精心设计和优化，聚焦于复杂问题的特定方面，从而产出更准确、更有针对性的结果。

前一步骤的输出作为后一步骤的输入，这一点至关重要。这种信息传递构建了一个依赖链（“提示词链”由此得名），在该链条中，先前操作的上下文和结果会指导后续的处理过程。这使得大型语言模型能够基于之前的工作成果继续推进，深化理解，并逐步接近预期的解决方案。

此外，提示词链不仅用于拆解问题，还能实现外部知识与工具的整合。在每个步骤中，可指示大型语言模型与外部系统、应用程序编程接口（APIs）或数据库进行交互，从而丰富其知识储备、拓展能力边界，使其不再局限于内部训练数据。这一能力极大地拓展了大型语言模型的应用潜力，使其不再只是孤立的模型，而是成为更庞大、更智能系统中不可或缺的组成部分。

提示词链的意义远超简单的问题解决。它是构建复杂人工智能代理（AI Agents）的基础技术。这些代理可利用提示词链在动态环境中自主规划、推理和行动。通过对提示词序列进行策略性构建，代理能够完成需要多步推理、规划和决策的任务。此类代理的工作流程能更贴近人类的思维过程，从而在复杂领域和系统中实现更自然、更高效的交互。

### 单一提示词的局限性
对于多方面的复杂任务，为大型语言模型使用单一、复杂的提示词效率低下，可能导致模型难以应对约束条件和指令要求，进而引发多种问题：指令遗漏（提示词的部分内容被忽略）、上下文偏移（模型偏离初始上下文）、错误传播（早期错误被放大）、提示词需更长上下文窗口（模型获取的信息不足以生成回应），以及幻觉（认知负荷增加导致生成错误信息的概率上升）。例如，若要求模型“分析一份市场调研报告、总结结论、结合数据点识别趋势并撰写邮件”，该任务很可能失败——模型或许能做好总结，但可能无法准确提取数据，或无法恰当撰写邮件。

### 通过顺序拆解提升可靠性
提示词链通过将复杂任务拆解为聚焦式的顺序工作流程，解决了上述问题，显著提升了可靠性和可控性。以刚才的例子为例，采用流水线式（或链式）的处理方式可分为以下步骤：
1. **初始提示词（总结阶段）**：“总结以下市场调研报告的核心结论：[文本内容]。”此时模型仅专注于总结任务，提升了初始步骤的准确性。
2. **第二个提示词（趋势识别阶段）**：“基于上述总结，识别三大新兴趋势，并提取支持每个趋势的具体数据点：[步骤1的输出结果]。”该提示词的约束条件更明确，且直接基于已验证的输出结果展开。
3. **第三个提示词（邮件撰写阶段）**：“撰写一封简洁的邮件给营销团队，概述以下趋势及其支持数据：[步骤2的输出结果]。”

这种拆解方式实现了对流程更精细的控制。每个步骤更简单、歧义更少，减轻了模型的认知负荷，最终产出更准确、更可靠的结果。这种模块化类似于计算流水线——每个函数执行特定操作后，再将结果传递给下一个函数。为确保每个特定任务都能得到准确回应，可在每个阶段为模型分配不同的“角色”。例如，在上述场景中，初始提示词可指定模型为“市场分析师”，后续提示词指定为“行业分析师”，第三个提示词指定为“专业文案撰写者”，依此类推。

### 结构化输出的作用
提示词链的可靠性在很大程度上依赖于步骤间传递数据的完整性。若某个提示词的输出模糊不清或格式混乱，下一个提示词可能会因输入错误而失效。为规避这一问题，指定结构化的输出格式（如JSON或XML）至关重要。

例如，趋势识别步骤的输出可格式化为以下JSON对象：
```json
{
  "trends": [
    {
      "trend_name": "人工智能驱动的个性化服务",
      "supporting_data": "73%的消费者更愿意与那些利用个人信息优化购物体验、提升相关性的品牌合作。"
    },
    {
      "trend_name": "可持续与道德品牌",
      "supporting_data": "带有环境、社会和公司治理（ESG）相关声明的产品销售额在过去五年增长了28%，而无此类声明的产品增长率仅为20%。"
    }
  ]
}
```
这种结构化格式确保数据具备机器可读性，能被精准解析并传入下一个提示词，避免歧义。该做法减少了因解读自然语言而产生的错误，是构建稳健的多步骤大型语言模型系统的关键环节。

## 实际应用场景
提示词链是一种多用途模式，在构建智能代理系统时可应用于广泛场景。其核心价值在于将复杂问题拆解为顺序化、可管理的步骤。以下是若干实际应用案例：

### 1. 信息处理工作流程
许多任务需要对原始信息进行多轮转换处理。例如，总结文档、提取关键实体，再利用这些实体查询数据库或生成报告。对应的提示词链可设计为：
- 提示词1：从给定的网址或文档中提取文本内容。
- 提示词2：总结提取后的清晰文本。
- 提示词3：从总结内容或原始文本中提取特定实体（如姓名、日期、地点）。
- 提示词4：利用提取的实体搜索内部知识库。
- 提示词5：整合总结内容、实体信息和搜索结果，生成最终报告。

该方法可应用于多个领域，如自动化内容分析、人工智能驱动的研究助手开发，以及复杂报告生成。

### 2. 复杂查询解答
解答需要多步推理或信息检索的复杂问题，是提示词链的典型应用场景。例如，对于问题“1929年股市崩盘的主要原因是什么？政府政策如何应对？”，提示词链可设计为：
- 提示词1：拆解用户查询中的核心子问题（崩盘原因、政府应对措施）。
- 提示词2：专门研究或检索与1929年股市崩盘原因相关的信息。
- 提示词3：专门研究或检索与政府针对1929年股市崩盘的政策应对相关的信息。
- 提示词4：整合步骤2和步骤3的信息，形成对原始查询的连贯解答。

这种顺序处理方法是开发具备多步推理和信息整合能力的人工智能系统的核心。当一个查询无法通过单一数据点解答，而需要一系列逻辑步骤或整合多来源信息时，就需要此类系统。

例如，一个用于生成特定主题综合报告的自动化研究代理，会执行混合计算工作流程：首先，系统检索大量相关文章；接着，从每篇文章中提取关键信息——这一步适合并行处理，即同时执行多个独立子任务以最大化效率。

然而，当各个独立的信息提取完成后，流程会转向固有的顺序化处理：系统必须先整理提取的数据，再将其整合为连贯的报告初稿，最后审核并修订初稿以生成最终报告。后续的每个阶段在逻辑上都依赖于前一阶段的成功完成，这正是提示词链的用武之地：整理后的数据作为“整合提示词”的输入，生成的整合文本再作为“最终审核提示词”的输入。因此，复杂操作通常会结合并行处理（用于独立数据收集）和提示词链（用于依赖性的整合与修订步骤）。

### 3. 数据提取与转换
将非结构化文本转换为结构化格式通常需要迭代过程，通过顺序化修改提高输出的准确性和完整性。对应的提示词链可设计为：
- 提示词1：尝试从发票文档中提取特定字段（如姓名、地址、金额）。
- 处理步骤：检查是否已提取所有必填字段，且字段格式是否符合要求。
- 提示词2（条件性提示词）：若存在字段缺失或格式错误，生成新的提示词，要求模型专门查找缺失/格式错误的信息（可提供前次提取失败的相关上下文）。
- 处理步骤：再次验证结果，必要时重复上述过程。
- 输出：生成提取完成且经过验证的结构化数据。

这种顺序处理方法尤其适用于从非结构化来源（如表单、发票、邮件）中提取和分析数据。例如，解决复杂的光学字符识别（OCR）问题（如处理PDF表单）时，采用拆解后的多步骤方法会更高效。

首先，利用大型语言模型从文档图像中执行初步文本提取；接着，模型对原始输出进行数据标准化处理——例如，将“一千零五十”这类文字形式的数字转换为数值“1050”。大型语言模型在执行精确数学计算时存在明显短板，因此在后续步骤中，系统可将所需的算术运算委托给外部计算器工具：大型语言模型识别出需要计算的内容，将标准化后的数字传入工具，再整合工具返回的精确结果。这种“文本提取→数据标准化→外部工具调用”的链式流程，能实现单一大型语言模型查询通常难以可靠获得的准确结果。

### 4. 内容生成工作流程
复杂内容的创作是一项程序性任务，通常需拆解为不同阶段，包括初步构思、结构提纲、初稿撰写和后续修订。对应的提示词链可设计为：
- 提示词1：根据用户的大致兴趣，生成5个主题构思。
- 处理步骤：允许用户选择一个构思，或自动筛选最优构思。
- 提示词2：基于选定的主题，生成详细的内容提纲。
- 提示词3：根据提纲的第一个要点，撰写内容初稿。
- 提示词4：根据提纲的第二个要点撰写内容初稿，并提供前一部分内容作为上下文；对提纲中的所有要点重复此步骤。
- 提示词5：审核并修订完整初稿，确保逻辑连贯、语气恰当且语法正确。

该方法可应用于多种自然语言生成任务，如自动化创作创意故事、撰写技术文档，以及生成其他形式的结构化文本内容。

### 5. 带状态的对话代理
尽管全面的状态管理架构会采用比顺序链接更复杂的方法，但提示词链为保持对话连贯性提供了基础机制。该技术通过将每次对话轮次构建为新的提示词，系统地整合对话序列中先前交互的信息或提取的实体，从而维持上下文。对应的提示词链可设计为：
- 提示词1：处理用户的第1轮表述，识别用户意图和关键实体。
- 处理步骤：用识别出的意图和实体更新对话状态。
- 提示词2：基于当前对话状态，生成回应和/或确定下一步需要获取的信息。
- 对后续每一轮对话重复上述过程：用户的每一次新表述都会触发一个提示词链，该链条会利用不断累积的对话历史（状态）。

这一原理是开发对话代理的核心——它能让代理在多轮扩展对话中维持上下文和逻辑连贯性。通过保留对话历史，系统能够理解并恰当回应那些依赖先前交流信息的用户输入。

### 6. 代码生成与优化
功能性代码的生成通常是多阶段过程，需将问题拆解为一系列离散的逻辑操作，并逐步执行。对应的提示词链可设计为：
- 提示词1：理解用户对代码函数的需求，生成伪代码或代码框架。
- 提示词2：基于框架撰写初始代码草稿。
- 提示词3：识别代码中潜在的错误或可优化点（可调用静态分析工具或另一大型语言模型）。
- 提示词4：根据识别出的问题重写或优化代码。
- 提示词5：为代码添加文档说明或测试用例。

在人工智能辅助软件开发等应用中，提示词链的价值体现在它能将复杂编码任务拆解为一系列可管理的子问题。这种模块化结构降低了大型语言模型在每个步骤中的操作复杂度；更关键的是，该方法允许在模型调用之间嵌入确定性逻辑，从而在工作流程中实现中间数据处理、输出验证和条件分支。通过这种方式，一个可能导致不可靠或不完整结果的单一、多方面需求，被转化为由底层执行框架管理的结构化操作序列。

### 7. 多模态与多步推理
分析多模态数据集（包含多种数据类型）需要将问题拆解为基于提示词的小型任务。例如，解读一张包含图片（图片中嵌入文本）、标注（突出显示特定文本片段）和表格数据（解释每个标注含义）的图像，就需要采用这种方法。对应的提示词链可设计为：
- 提示词1：从用户的图像请求中提取并理解文本内容。
- 提示词2：将提取的图像文本与其对应的标注关联起来。
- 提示词3：利用表格解读收集到的信息，确定所需输出。

## 实操代码示例
实现提示词链的方式多样，既可以在脚本中直接进行顺序函数调用，也可以利用专门的框架（用于管理控制流、状态和组件集成）。LangChain、LangGraph、Crew AI和谷歌代理开发工具包（Google Agent Development Kit，ADK）等框架提供了结构化环境，用于构建和执行这些多步骤流程——这在处理复杂架构时尤为有利。

为便于演示，LangChain和LangGraph是合适的选择，因为它们的核心API专为组合操作链和操作图而设计：LangChain为线性序列提供基础抽象，LangGraph则扩展了这些能力，支持有状态和循环计算（这是实现更复杂智能代理行为的必要条件）。本示例将聚焦于基础的线性序列。

以下代码实现了一个两步提示词链，用作数据处理流水线：第一阶段用于解析非结构化文本并提取特定信息，第二阶段接收提取的输出并将其转换为结构化数据格式。

要复现此流程，需先安装所需库，可通过以下命令完成：
```bash
pip install langchain langchain-community langchain-openai langgraph
```
注意：`langchain-openai`可替换为其他模型提供商对应的合适包。随后，需在执行环境中配置所选语言模型提供商（如OpenAI、谷歌Gemini、Anthropic）所需的API密钥。

```python
import os
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# 为提升安全性，可从.env文件加载环境变量
# from dotenv import load_dotenv
# 确保在.env文件中设置了OPENAI_API_KEY
# load_dotenv()

# 初始化语言模型（推荐使用ChatOpenAI）
llm = ChatOpenAI(temperature=0)

# --- 提示词1：提取信息 ---
prompt_extract = ChatPromptTemplate.from_template(
    "从以下文本中提取技术规格：\n\n{text_input}"
)

# --- 提示词2：转换为JSON格式 ---
prompt_transform = ChatPromptTemplate.from_template(
    "将以下规格转换为JSON对象，包含'cpu'、'memory'和'storage'三个键：\n\n{specifications}"
)

# --- 使用LCEL构建提示词链 ---
# StrOutputParser()将大型语言模型的消息输出转换为简单字符串
extraction_chain = prompt_extract | llm | StrOutputParser()

# 完整链条：将提取链条的输出作为转换提示词的'specifications'变量输入
full_chain = (
    {"specifications": extraction_chain}
    | prompt_transform
    | llm
    | StrOutputParser()
)

# --- 运行提示词链 ---
input_text = "这款新笔记本电脑型号配备3.5GHz八核处理器、16GB内存和1TB NVMe固态硬盘。"

# 传入输入文本字典，执行链条
final_result = full_chain.invoke({"text_input": input_text})

print("\n--- 最终JSON输出 ---")
print(final_result)
```

这段Python代码演示了如何使用LangChain库处理文本：它采用两个独立的提示词——一个用于从输入字符串中提取技术规格，另一个用于将这些规格格式化为JSON对象。其中，ChatOpenAI模型用于处理语言模型交互，StrOutputParser确保输出为可用的字符串格式。

代码通过LangChain表达式语言（LangChain Expression Language，LCEL）将这些提示词和语言模型优雅地链接起来：第一个链条`extraction_chain`负责提取规格，完整链条`full_chain`则将提取结果作为输入，传入转换提示词。代码中提供了一段描述笔记本电脑的示例输入文本，调用`full_chain`对其进行两步处理后，最终打印出包含提取并格式化后规格的JSON字符串。

## 上下文工程与提示词工程
上下文工程（见图1）是一门系统性学科，旨在在人工智能模型生成令牌（token）之前，设计、构建并提供完整的信息环境。该方法认为，模型输出的质量较少依赖于模型架构本身，更多取决于所提供上下文的丰富程度。

![fig_31692](https://p3-flow-imagex-sign.byteimg.com/ocean-cloud-tos/pdf/8c84d34afc3ca9a2e5e16b6a34b9a49e_8_1200.jpg~tplv-a9rns2rl98-resize-crop:230:485:702:869:472:384.jpeg?rk3s=1567c5c4&x-expires=1791594792&x-signature=oXNCfOGuMtZh9UFPWlrM7RjmPgQ%3D)

图1：上下文工程是为人工智能构建丰富、全面信息环境的学科，该上下文的质量是实现高级智能代理性能的主要因素。

上下文工程是对传统提示词工程的重大革新：传统提示词工程主要聚焦于优化用户即时查询的表述方式，而上下文工程则将范围扩展到多层信息，包括系统提示词（定义人工智能操作参数的基础指令集，例如“你是一名技术 writer，语气需正式、严谨”）。

上下文还会通过外部数据进一步丰富，包括：
- 检索到的文档：人工智能主动从知识库中获取信息以辅助生成回应（如为某个项目调取技术规格）；
- 工具输出：人工智能通过调用外部API获取实时数据的结果（如查询日历以确认用户的可用时间）。

这些显性数据会与关键的隐性数据（如用户身份、交互历史、环境状态）相结合。其核心原则是：即使是先进的模型，若只能获取有限或构建不佳的操作环境信息，也会表现不佳。

因此，这种实践将任务重心从“单纯回答问题”转变为“为智能代理构建全面的操作图景”。例如，一个经过上下文工程设计的智能代理，在回应查询时，会先整合用户的日历可用时间（工具输出）、与邮件接收者的职业关系（隐性数据）以及先前会议记录（检索到的文档）——这样生成的输出会更具相关性、个性化和实用价值。

“工程”层面的工作包括：构建稳健的流水线以在运行时获取和转换数据，建立反馈循环以持续提升上下文质量。

要实现这一点，可使用专门的调优系统来规模化自动化改进过程。例如，谷歌Vertex AI提示词优化器这类工具，通过根据一组样本输入和预定义评估指标系统地评估模型回应，能有效提升模型性能。这种方法无需大量手动重写，即可实现跨不同模型的提示词和系统指令适配。向优化器提供样本提示词、系统指令和模板后，它能以程序化方式优化上下文输入，为实现复杂上下文工程所需的反馈循环提供了结构化方法。

这种结构化方法正是“基础人工智能工具”与“更复杂、具备上下文感知能力的系统”的区别所在。它将上下文本身视为核心组件，高度重视“智能代理知道什么、何时知道以及如何利用这些信息”。通过这种实践，模型能全面理解用户意图、交互历史和当前环境，最终将无状态聊天机器人升级为功能强大、具备情境感知能力的系统——上下文工程正是实现这一升级的关键方法。

## 核心概览
### 问题所在（What）
当复杂任务通过单一提示词处理时，大型语言模型常因负荷过重而表现不佳：模型的认知负荷增加，会提高其忽略指令、偏离上下文、生成错误信息的概率。单一提示词难以有效管理多重约束条件和顺序推理步骤，最终导致输出不可靠、不准确——模型无法全面应对多方面需求的所有维度。

### 解决思路（Why）
提示词链通过将复杂问题拆解为一系列相互关联的小型子任务，提供了标准化解决方案。链中的每个步骤都使用聚焦式提示词执行特定操作，显著提升了可靠性和可控性。前一个提示词的输出作为下一个的输入，形成逻辑工作流程，逐步推进以实现最终解决方案。这种“分而治之”的模块化策略，让流程更易于管理和调试，还允许在步骤间整合外部工具或结构化数据格式。该模式是开发复杂多步骤智能代理系统的基础——这类系统能实现规划、推理和复杂工作流程执行。

### 经验法则（Rule of Thumb）
当出现以下情况时，可采用该模式：
- 任务过于复杂，无法通过单一提示词完成；
- 任务涉及多个不同的处理阶段；
- 步骤间需要与外部工具交互；
- 构建需要执行多步推理并维持状态的智能代理系统。

### 可视化总结
![fig_59467](https://p3-flow-imagex-sign.byteimg.com/ocean-cloud-tos/pdf/8c84d34afc3ca9a2e5e16b6a34b9a49e_11_1200.jpg~tplv-a9rns2rl98-resize-crop:267:155:665:566:398:411.jpeg?rk3s=1567c5c4&x-expires=1791594792&x-signature=9irkXwgyJrP70GZonWuqVMxvvzs%3D)

图2：提示词链模式：智能代理接收用户的一系列提示词，每个代理的输出作为链中下一个代理的输入。

## 核心要点
以下是核心要点总结：
- 提示词链将复杂任务拆解为一系列更小、更聚焦的步骤，有时也被称为“流水线模式”。
- 链中的每个步骤都涉及一次大型语言模型调用或一段处理逻辑，且会将前一步骤的输出作为输入。
- 该模式提升了与语言模型进行复杂交互时的可靠性和可管理性。
- LangChain/LangGraph、谷歌ADK等框架提供了稳健的工具，用于定义、管理和执行这些多步骤序列。

## 结论
通过将复杂问题拆解为一系列更简单、更易于管理的子任务，提示词链为引导大型语言模型提供了稳健框架。这种“分而治之”的策略让模型每次聚焦于单一特定操作，显著提升了输出的可靠性和可控性。作为基础模式，它支持开发具备多步推理、工具整合和状态管理能力的复杂人工智能代理。最终，掌握提示词链是构建稳健、具备上下文感知能力的系统的关键——这类系统能执行复杂工作流程，远超单一提示词的能力范围。

## 参考资料
1. LangChain关于LCEL的文档：https://python.langchain.com/v0.2/docs/core_modules/expression_language/
2. LangGraph文档：https://langchain-ai.github.io/langgraph/
3. 提示词工程指南——提示词链：https://www.promptingguide.ai/techniques/chaining
4. OpenAI API文档（通用提示词概念）：https://platform.openai.com/docs/guides/gpt/prompting
5. Crew AI文档（任务与流程）：https://docs.crewai.com/
6. 谷歌开发者人工智能（提示词指南）：https://cloud.google.com/discover/what-is-prompt-engineering?hl=en
7. Vertex提示词优化器：https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-optimizer
